# Event Schemas v1

**Status**: Draft
**Date**: 2025-12-28
**Owner**: niko

## Overview

This document defines the standard event schemas used in NorthstarDB's Review & Observability system. Events are typed, versioned, and time-travel-compatible append-only records that are logically separate from the hot commit path.

## Key Principles

1. **Hot Path Safety**: Event payloads must be bounded and should not degrade core database performance
2. **Correlation**: Events include correlation hints for linking to commits and sessions
3. **Versioning**: Event schemas include version information for forward compatibility
4. **Retention**: Events have configurable retention policies

## Standard Event Types

### Performance Events

#### `perf.sample`

Individual performance metric sample with dimensions and correlation hints.

**Purpose**: Record performance measurements (latency, throughput, resource usage)

**Payload Format** (null-delimited strings):
```
metric_name\0value\0unit\0timestamp_ns\0commit_range\0session_count\0dimensions_json
```

**Fields**:
- `metric_name` (string): Metric identifier (e.g., "latency_ms", "throughput_ops")
- `value` (float64): Metric value
- `unit` (string): Unit of measurement (e.g., "ms", "ops/sec", "bytes")
- `timestamp_ns` (int64): Unix nanosecond timestamp of the sample
- `commit_range` (string, optional): Commit range in format "abc123..def456"
- `session_count` (uint32): Number of related sessions
- `dimensions_json` (string, optional): JSON object with dimensions (e.g., `{"operation":"read","table":"users"}`)

**Example**:
```
latency_ms\05.2\0ms\01704000000000000\0abc123..def456\01\0{"operation":"read","table":"users"}
```

**Size Limits**:
- Maximum payload: 4KB
- Maximum dimensions: 10 key-value pairs
- Maximum dimension value length: 256 bytes

**Retention**: Default 7 days, configurable per metric

#### `perf.regression`

Performance regression alert generated by automatic detection.

**Purpose**: Alert when performance degradation exceeds thresholds

**Payload Format**:
```
metric_name\0baseline_value\0current_value\0regression_percent\0severity\0timestamp_ns\0likely_cause
```

**Fields**:
- `metric_name` (string): Metric that regressed
- `baseline_value` (float64): Expected/baseline value
- `current_value` (float64): Current degraded value
- `regression_percent` (float): Percentage regression (e.g., 15.5 for 15.5% degradation)
- `severity` (string): "minor", "moderate", "severe", "critical"
- `timestamp_ns` (int64): When regression was detected
- `likely_cause` (string, optional): Correlated commit or change

**Size Limits**:
- Maximum payload: 2KB
- `likely_cause` max length: 512 bytes

**Retention**: Default 90 days (alerts kept longer than samples)

### Agent Lifecycle Events

#### `agent.session.started`

Agent session initialization event.

**Purpose**: Track agent activity sessions for attribution and debugging

**Payload Format**:
```
agent_id\0agent_version\0session_purpose\0metadata_json
```

**Fields**:
- `agent_id` (uint64): Unique agent identifier
- `agent_version` (string): Agent software version
- `session_purpose` (string): Reason for session (e.g., "code_review", "debugging")
- `metadata_json` (string, optional): Additional session metadata

**Size Limits**:
- Maximum payload: 2KB
- `metadata_json` max length: 1KB

**Retention**: Default 30 days

#### `agent.operation`

Individual agent operation event.

**Purpose**: Track individual operations performed by agents

**Payload Format**:
```
operation_type\0operation_id\0target_type\0target_id\0status\0duration_ns\0metadata_json
```

**Fields**:
- `operation_type` (string): Type of operation (e.g., "commit", "query", "analyze")
- `operation_id` (uint64): Unique operation identifier
- `target_type` (string): What the operation targets (e.g., "file", "symbol", "cartridge")
- `target_id` (string): Identifier for the target
- `status` (string): Operation status ("started", "completed", "failed")
- `duration_ns` (int64, optional): Operation duration in nanoseconds
- `metadata_json` (string, optional): Additional metadata

**Size Limits**:
- Maximum payload: 2KB
- `metadata_json` max length: 1KB

**Retention**: Default 30 days

### Review Events

#### `review.note`

Code review note attached to a target.

**Purpose**: Store review feedback on commits, files, symbols, etc.

**Payload Format**:
```
author_id\0target_type\0target_id\0note_text\0visibility\0created_at_ns\0reference_count\0references
```

**Fields**:
- `author_id` (uint64): Agent or human ID of the author
- `target_type` (string): "commit", "file", "symbol", "pr"
- `target_id` (string): Commit hash, file path, symbol name, etc.
- `note_text` (string): Review note content
- `visibility` (uint8): 0=private, 1=team, 2=public
- `created_at_ns` (int64): Creation timestamp
- `reference_count` (uint32): Number of references
- `references` (string[]): Comma-separated list of reference IDs

**Size Limits**:
- Maximum payload: 16KB (notes can be longer than metrics)
- `note_text` max length: 8KB
- Maximum references: 20

**Retention**: Default 365 days (reviews kept long-term)

#### `review.summary`

Generated review summary from LLM.

**Purpose**: Store AI-generated review summaries

**Payload Format**:
```
generator_id\0target_type\0target_id\0summary_text\0confidence\0model_id\0prompt_hash\0created_at_ns
```

**Fields**:
- `generator_id` (uint64): Agent ID that generated the summary
- `target_type` (string): What was reviewed
- `target_id` (string): Identifier for the target
- `summary_text` (string): Generated summary
- `confidence` (float): Confidence score 0.0-1.0
- `model_id` (string): LLM model used
- `prompt_hash` (string, optional): Hash of prompt used for reproducibility
- `created_at_ns` (int64): Generation timestamp

**Size Limits**:
- Maximum payload: 32KB
- `summary_text` max length: 16KB

**Retention**: Default 90 days

### Debug Events

#### `debug.session`

Debugger session capture event.

**Purpose**: Track debugging sessions linked to code

**Payload Format**:
```
tool\0session_id\0breakpoint_count\0breakpoints_json\0stack_summary\0commit_count\0commits\0symbol_count\0symbols
```

**Fields**:
- `tool` (string): Debugger name ("lldb", "gdb", "python-debugger")
- `session_id` (uint64): Unique session identifier
- `breakpoint_count` (uint32): Number of breakpoints
- `breakpoints_json` (string): JSON array of breakpoints
- `stack_summary` (string, optional): Sampled stack trace
- `commit_count` (uint32): Number of related commits
- `commits` (string[]): Comma-separated commit hashes
- `symbol_count` (uint32): Number of related symbols
- `symbols` (string[]): Comma-separated symbol names

**Size Limits**:
- Maximum payload: 64KB
- `stack_summary` max length: 4KB
- Maximum breakpoints: 50

**Retention**: Default 30 days

#### `debug.snapshot`

Debug state snapshot event.

**Purpose**: Capture program state at a point in time

**Payload Format**:
```
session_id\0timestamp_ns\0snapshot_type\0data_json
```

**Fields**:
- `session_id` (uint64): Parent debug session
- `timestamp_ns` (int64): Snapshot timestamp
- `snapshot_type` (string): "stack", "memory", "registers", "variables"
- `data_json` (string): Snapshot data as JSON

**Size Limits**:
- Maximum payload: 256KB
- `data_json` max length: 250KB

**Retention**: Default 7 days

### VCS Events

#### `vcs.commit`

Version control commit event.

**Purpose**: Track commits for correlation with performance and reviews

**Payload Format**:
```
commit_hash\0author_id\0commit_message\0file_count\0files\0parent_count\0parents\0branch\0timestamp_ns
```

**Fields**:
- `commit_hash` (string): Full commit hash
- `author_id` (uint64): Agent or human ID
- `commit_message` (string): Commit message
- `file_count` (uint32): Number of changed files
- `files` (string[]): Comma-separated file paths
- `parent_count` (uint32): Number of parent commits
- `parents` (string[]): Comma-separated parent hashes
- `branch` (string): Branch name
- `timestamp_ns` (int64): Commit timestamp

**Size Limits**:
- Maximum payload: 16KB
- `commit_message` max length: 4KB
- Maximum files: 100

**Retention**: Default 365 days

## Dimension Standards

Performance metrics should use standardized dimensions for consistency:

### Common Dimensions

| Dimension | Description | Example Values |
|-----------|-------------|----------------|
| `operation` | Operation type | "read", "write", "scan" |
| `table` | Table name | "users", "orders" |
| `index` | Index used | "idx_user_id", "primary" |
| `codepath` | Code path | "btree_search", "pager_read" |
| `cache_hit` | Cache result | "true", "false" |
| `error_type` | Error type | "timeout", "corruption", "not_found" |

### Agent Dimensions

| Dimension | Description | Example Values |
|-----------|-------------|----------------|
| `agent_id` | Agent identifier | "claude-opus", "task-master" |
| `session_id` | Session identifier | Session UUID |
| `plugin` | Plugin name | "perf_analyzer", "code_review" |

## Correlation Hints

Events may include correlation hints to link to commits and sessions:

### Commit Range Format

Format: `<start_hash>..<end_hash>`

Example: `abc123..def456` (commits from abc123 to def456 inclusive)

### Session IDs

Array of session identifiers that correlate with the event.

Example: `[1001, 1002, 1005]`

## Size Enforcement

### Payload Size Limits by Event Type

| Event Type | Max Payload | Rationale |
|------------|-------------|-----------|
| `perf.sample` | 4KB | High frequency, must stay small |
| `perf.regression` | 2KB | Lower frequency, moderate size |
| `agent.session.started` | 2KB | Low frequency, metadata |
| `agent.operation` | 2KB | Medium frequency, tracking |
| `review.note` | 16KB | Important, need space for text |
| `review.summary` | 16KB | Generated, moderate size |
| `debug.session` | 64KB | Complex data, debugging |
| `debug.snapshot` | 256KB | Large state dumps |
| `vcs.commit` | 16KB | Commit metadata |

### Sampling for High-Frequency Events

Events like `perf.sample` may be sampled to reduce volume:

- **Default sampling rate**: 100% (1.0)
- **Recommended for production**: 10% (0.1) for high-frequency metrics
- **Sampling method**: Random uniform sampling

### Rate Limiting

Events may be rate-limited per metric key:

- **Default rate limit**: 1000 events/second per key
- **Burst tolerance**: 10x rate limit for short bursts
- **Exceeded behavior**: Drop events with warning log

## Retention Policies

### Default Retention by Event Type

| Event Type | Default Retention | Rationale |
|------------|-------------------|-----------|
| `perf.sample` | 7 days | Short-term needed for regression detection |
| `perf.regression` | 90 days | Important to keep for historical analysis |
| `agent.session.started` | 30 days | Useful for debugging and attribution |
| `agent.operation` | 30 days | Medium-term audit trail |
| `review.note` | 365 days | Long-term knowledge retention |
| `review.summary` | 90 days | Generated, less critical than notes |
| `debug.session` | 30 days | Short-term debugging needs |
| `debug.snapshot` | 7 days | Large, quickly obsolete |
| `vcs.commit` | 365 days | Permanent correlation data |

### Retention Enforcement

- Events older than retention period are removed during compaction
- Compaction runs daily by default
- Manual compaction can be triggered via API

## Versioning

Event schemas include version information:

### Schema Version Format

`events_v<major>_<minor>`

Examples:
- `events_v1_0` (this document)
- `events_v1_1` (backwards compatible additions)
- `events_v2_0` (breaking changes)

### Compatibility Rules

- **Major version**: Breaking changes, not backwards compatible
- **Minor version**: Additions only, backwards compatible

### Event Version Header

Each event includes a schema version in its header for parsing:

```
event_type: perf.sample
schema_version: 1_0
```

## Migration Guide

### Upgrading from v1_0 to v1_1

1. Add new optional fields to existing event parsers
2. Old events without new fields should use default values
3. New events can include new fields
4. No breaking changes to existing fields

### Example: Adding a new dimension

```zig
// Old parser
const sample = parsePerfSample(payload);

// New parser (backwards compatible)
const sample = parsePerfSampleV1_1(payload);
// New field "cache_hit" defaults to null if not present
```

## Error Handling

### Invalid Event Payloads

Events with invalid payloads should:

1. Log a warning with event ID
2. Skip the event (don't crash)
3. Increment error counter
4. Continue processing other events

### Missing Optional Fields

Optional fields that are missing should:

1. Use null/empty defaults
2. Not log errors (expected case)
3. Document null handling in queries

### Corrupted Event Storage

If event storage corruption is detected:

1. Log error with file offset
2. Skip corrupted event
3. Continue with next event
4. Trigger rebuild if corruption rate > 1%

## Security Considerations

### Sensitive Data Redaction

Events that may contain sensitive data:

- `debug.session`: May contain variable values
- `agent.operation`: May contain file contents in metadata
- `review.note`: May contain sensitive code

**Redaction Rules**:
- Credit card numbers: Replace with `****`
- API keys: Replace with `[REDACTED]`
- Passwords: Replace with `[REDACTED]`
- Personal info: Replace with `[REDACTED]`

### Visibility Levels

Events support visibility levels:

- **Private** (0): Only visible to creating agent
- **Team** (1): Visible within team
- **Public** (2): Visible to all

**Default Visibility**:
- `perf.*`: Team
- `agent.*`: Private
- `review.*`: Team (notes), Public (summaries)
- `debug.*`: Private
- `vcs.*`: Public

## Appendix A: Event Type Constants

```zig
pub const EventType = enum(u16) {
    // Agent lifecycle events
    agent_session_started = 0x1000,
    agent_session_ended = 0x1001,
    agent_operation = 0x1002,

    // Review events
    review_note = 0x2000,
    review_summary = 0x2001,

    // Performance events
    perf_sample = 0x3000,
    perf_regression = 0x3001,

    // Debug events
    debug_session = 0x4000,
    debug_snapshot = 0x4001,

    // VCS events
    vcs_commit = 0x5000,
    vcs_branch = 0x5001,
};
```

## Appendix B: Sample Event Payloads

### Performance Sample

```
latency_ms\05.234\0ms\01704000000000000\0abc123..def456\01\0{"operation":"read","table":"users","index":"idx_user_id"}
```

### Review Note

```
42\0commit\0abc123\0\0This commit introduces a potential race condition in the B+tree split logic.\0\1\01704000000000000\0\0
```

### Regression Alert

```
latency_ms\010.0\015.5\055.0\0moderate\01704000000000000\0Commit abc123 increased B+tree search latency
```

### Agent Operation

```
analyze\01234\0file\0src/btree.zig\0completed\0150000000\0{"lines_analyzed":1500}
```

## Appendix C: Query Examples

### Find regressions in last 24 hours

```zig
const results = try event_manager.query(.{
    .event_types = &[_]EventType{.perf_regression},
    .start_time = std.time.nanoTimestamp() - (24 * 60 * 60 * 1_000_000_000),
});
```

### Get all review notes for a commit

```zig
const notes = try code_review_cartridge.getCommitReviews("abc123");
```

### Get performance samples for a session

```zig
const samples = try observability_cartridge.getSessionMetrics(session_id, 100);
```

### Find operations by agent

```zig
const events = try event_manager.getActorEvents(agent_id, 50);
```
